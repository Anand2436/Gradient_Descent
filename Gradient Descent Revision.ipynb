{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"data.csv\",delimiter=\",\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = data[:,0:-1]\n",
    "#x1 = pd.DataFrame(x)\n",
    "\n",
    "#c = np.ones(100)\n",
    "#x1.insert(loc = 1,column = 1,value = c)\n",
    "y = data[:,1]\n",
    "#y1 = pd.DataFrame(y)\n",
    "#x = x1.values\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train, y_test = train_test_split(x,y,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cost(x, y, theta):\n",
    "    \n",
    "    M = len(y)\n",
    "    \n",
    "    total_cost = ((np.matmul(x,theta)-y)**2).sum() / M;\n",
    "    \n",
    "    print(total_cost)\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Will be called from fit Gradient function \n",
    "# therefore no need to add a column of 1s for calculation of c\n",
    "\n",
    "def linear_hypothesis(X, theta):\n",
    "    return np.matmul(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gd(x_train, y_train, itr = 1000 ,rate=0.001):\n",
    "    \n",
    "    M = len(y_train) # Count of entries in our data\n",
    "   # print(np.matmul(((y - ((m*x)+c)).T)).shape)\n",
    "    x_train = np.c_[x_train,np.ones(M)]\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    \n",
    "    fc = x_train.shape[1] # feature count\n",
    "    \n",
    "    theta = np.zeros(fc).reshape(-1,1)\n",
    "    \n",
    "    for i in range(itr):\n",
    "        linearPrediction = linear_hypothesis(x_train , theta) # calculating theta*x\n",
    "        error = linearPrediction - y_train\n",
    "        theta_slope = np.matmul(x_train.T,error) # (y-m*x) * x {slope wrt theta}\n",
    "        theta = theta - rate * theta_slope # subtracting the slope obtained to get to better results\n",
    "    \n",
    "        if (i+1) % 500 == 0:\n",
    "            #print(\"linear Prediction shape\",linearPrediction.shape)\n",
    "            #print(y_train.shape)\n",
    "            #print(\"error shape\",error.shape)\n",
    "            #print(\"theta slope shape\",theta_slope.shape)\n",
    "            #print(\"theta shape\",theta.shape)\n",
    "            print(\"Cost at\", i ,\"th iteration is \")\n",
    "            Cost(x_train , y_train,theta)\n",
    "            #print(\"Theta values\",theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_test , theta):\n",
    "    x_test = np.c_[x_test,np.ones(x_test.shape)] # adding a clumn of 1s for calculation of c\n",
    "    y_pred = np.matmul(x_test,theta)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    itr = 10000\n",
    "    #learning_rate = 0.000000000000000000000001\n",
    "    learning_rate = 1e-14\n",
    "    m = gd(x_train,y_train,itr,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 499 th iteration is \n",
      "5404.64297125\n",
      "Cost at 999 th iteration is \n",
      "5404.63308871\n",
      "Cost at 1499 th iteration is \n",
      "5404.62320619\n",
      "Cost at 1999 th iteration is \n",
      "5404.61332369\n",
      "Cost at 2499 th iteration is \n",
      "5404.6034412\n",
      "Cost at 2999 th iteration is \n",
      "5404.59355873\n",
      "Cost at 3499 th iteration is \n",
      "5404.58367628\n",
      "Cost at 3999 th iteration is \n",
      "5404.57379385\n",
      "Cost at 4499 th iteration is \n",
      "5404.56391144\n",
      "Cost at 4999 th iteration is \n",
      "5404.55402905\n",
      "Cost at 5499 th iteration is \n",
      "5404.54414667\n",
      "Cost at 5999 th iteration is \n",
      "5404.53426432\n",
      "Cost at 6499 th iteration is \n",
      "5404.52438198\n",
      "Cost at 6999 th iteration is \n",
      "5404.51449966\n",
      "Cost at 7499 th iteration is \n",
      "5404.50461736\n",
      "Cost at 7999 th iteration is \n",
      "5404.49473508\n",
      "Cost at 8499 th iteration is \n",
      "5404.48485281\n",
      "Cost at 8999 th iteration is \n",
      "5404.47497056\n",
      "Cost at 9499 th iteration is \n",
      "5404.46508834\n",
      "Cost at 9999 th iteration is \n",
      "5404.45520613\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 499 th iteration is \n",
      "23.5138795462\n",
      "Cost at 999 th iteration is \n",
      "23.4696338808\n",
      "Cost at 1499 th iteration is \n",
      "23.466336719\n",
      "Cost at 1999 th iteration is \n",
      "23.466073594\n",
      "Cost at 2499 th iteration is \n",
      "23.4660525725\n",
      "Cost at 2999 th iteration is \n",
      "23.4660508931\n",
      "Cost at 3499 th iteration is \n",
      "23.4660507589\n",
      "Cost at 3999 th iteration is \n",
      "23.4660507482\n",
      "Cost at 4499 th iteration is \n",
      "23.4660507473\n",
      "Cost at 4999 th iteration is \n",
      "23.4660507472\n",
      "Cost at 5499 th iteration is \n",
      "23.4660507472\n",
      "Cost at 5999 th iteration is \n",
      "23.4660507472\n",
      "Cost at 6499 th iteration is \n",
      "23.4660507472\n",
      "Cost at 6999 th iteration is \n",
      "23.4660507472\n",
      "Cost at 7499 th iteration is \n",
      "23.4660507472\n",
      "Cost at 7999 th iteration is \n",
      "23.4660507472\n",
      "Cost at 8499 th iteration is \n",
      "23.4660507472\n",
      "Cost at 8999 th iteration is \n",
      "23.4660507472\n",
      "Cost at 9499 th iteration is \n",
      "23.4660507472\n",
      "Cost at 9999 th iteration is \n",
      "23.4660507472\n"
     ]
    }
   ],
   "source": [
    "train = np.loadtxt(\"Boston Gradient Project/BostonXYtrain.csv\",delimiter=\",\")\n",
    "\n",
    "x = train[:,0:-1]\n",
    "y = train[:,-1]\n",
    "theta = gd(x,y,10000,rate=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
